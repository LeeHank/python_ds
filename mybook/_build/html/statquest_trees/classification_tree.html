
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>14. Classification Trees &#8212; My sample book</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="15. Permutation Importance vs Random Forest Feature Importance (MDI)" href="../sklearn_guide/rf_permutation_imp.html" />
    <link rel="prev" title="13. Supervised Learning with scikit-learn" href="../datacamp_su/datacamp_su.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">My sample book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Welcome to your Jupyter Book
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Numpy
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch2_numpy/official_beginner/official_beginner.html">
   1. Beginner (Official)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Pandas
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch3_pandas/official_getting_started/getting_started.html">
   2. Getting Started (official)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Matplotlib
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4_matplotlib/04.00-matplotlib_intro.html">
   3. Matplotlib 簡介與常用技巧
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4_matplotlib/04.01-Simple-Line-Plots.html">
   4. Simple Line Plots
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4_matplotlib/04.02-Simple-Scatter-Plots.html">
   5. Simple Scatter Plots
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4_matplotlib/04.03-Errorbars.html">
   6. Error bars &amp; Error region
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4_matplotlib/04.05-Histograms-and-Density.html">
   7. Histograms and Density
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4_matplotlib/04.06-Legends.html">
   8. Legends
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4_matplotlib/04.07-Colorbars.html">
   9. Colorbars
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4_matplotlib/04.08-Multiple-Subplots.html">
   10. Multiple Subplots
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Seaborn
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../datacamp_seaborn/intro_seaborn.html">
   11. Introduction to Seaborn
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  unsupervised learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../datacamp_unsu/clusters.html">
   12. Clustering
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  supervised learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../datacamp_su/datacamp_su.html">
   13. Supervised Learning with scikit-learn
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   14. Classification Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../sklearn_guide/rf_permutation_imp.html">
   15. Permutation Importance vs Random Forest Feature Importance (MDI)
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/statquest_trees/classification_tree.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fstatquest_trees/classification_tree.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/statquest_trees/classification_tree.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#import-the-modules">
   14.1. Import the modules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#import-the-data">
   14.2. Import the data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   14.3. 資料檢查 &amp; 清理
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#identify-deal-with-missing-data">
     14.3.1. identify &amp; deal with missing data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#format-data-part-1-y-and-x-form">
   14.4. Format Data Part 1: Y and X form
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#format-the-data-part-2-one-hot-encoding">
   14.5. Format the Data Part 2: One-Hot Encoding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bam">
   14.6. BAM!!!
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#double-bam">
   14.7. Double BAM!!!
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#build-a-preliminary-classification-tree">
   14.8. Build A Preliminary Classification Tree
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cost-complexity-pruning-part-1-visualize-alpha">
   14.9. Cost Complexity Pruning Part 1: Visualize alpha
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cost-complexity-pruning-part-2-cross-validation-for-finding-the-best-alpha">
   14.10. Cost Complexity Pruning Part 2: Cross Validation For Finding the Best Alpha
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#building-evaluating-drawing-and-interpreting-the-final-classification-tree">
   14.11. Building, Evaluating, Drawing, and Interpreting the Final Classification Tree
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#in-conclusion-we">
   14.12. In conclusion we…
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#triple-bam">
   14.13. TRIPLE BAM!!!
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Classification Trees</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#import-the-modules">
   14.1. Import the modules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#import-the-data">
   14.2. Import the data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   14.3. 資料檢查 &amp; 清理
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#identify-deal-with-missing-data">
     14.3.1. identify &amp; deal with missing data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#format-data-part-1-y-and-x-form">
   14.4. Format Data Part 1: Y and X form
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#format-the-data-part-2-one-hot-encoding">
   14.5. Format the Data Part 2: One-Hot Encoding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bam">
   14.6. BAM!!!
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#double-bam">
   14.7. Double BAM!!!
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#build-a-preliminary-classification-tree">
   14.8. Build A Preliminary Classification Tree
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cost-complexity-pruning-part-1-visualize-alpha">
   14.9. Cost Complexity Pruning Part 1: Visualize alpha
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cost-complexity-pruning-part-2-cross-validation-for-finding-the-best-alpha">
   14.10. Cost Complexity Pruning Part 2: Cross Validation For Finding the Best Alpha
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#building-evaluating-drawing-and-interpreting-the-final-classification-tree">
   14.11. Building, Evaluating, Drawing, and Interpreting the Final Classification Tree
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#in-conclusion-we">
   14.12. In conclusion we…
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#triple-bam">
   14.13. TRIPLE BAM!!!
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="classification-trees">
<h1><span class="section-number">14. </span>Classification Trees<a class="headerlink" href="#classification-trees" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>這堂課會用 <strong>scikit-learn</strong> and <strong>Cost Complexity Pruning</strong> 來建立 <strong>Classification Tree</strong></p></li>
<li><p>要使用的資料來自 <strong><a class="reference external" href="https://archive.ics.uci.edu/ml/index.php">UCI Machine Learning Repository</a></strong>  裡的 <strong><a class="reference external" href="https://archive.ics.uci.edu/ml/datasets/Heart+Disease">Heart Disease Dataset</a></strong></p></li>
<li><p>目標是：預測病人是否有 <strong><a class="reference external" href="https://archive.ics.uci.edu/ml/datasets/Heart+Disease">heart disease</a></strong> based on 這個人的性別、年齡、血壓、和各式各樣的 metrics.
<img alt="" src="../_images/tree.png" /></p></li>
</ul>
<ul class="simple">
<li><p><strong>Classification Trees</strong> 是一個很好解釋的模型，尤其是在你要跟你老闆或user報告，這個預測結果是怎麼來的的時候 (how the decisions are being made)</p></li>
<li><p>舉例來說，我預測某個病人有心臟病，且他是位於上圖的最右下角。那我的解釋就是：因為該病人屬於 {ca &gt; 0.5, cp&lt;=3.5, oldpeak &gt; 0.55} 這一組。而根據過去資料，這一組的13個病人中有 10 個病人都有心臟病，所以我預測他有心臟病。</p></li>
<li><p>這堂課會涵蓋到的主題：</p>
<ul>
<li><p><strong><a class="reference external" href="#download-the-data">Importing Data</a></strong></p></li>
<li><p><strong><a class="reference external" href="#identify-and-deal-with-missing-data">Missing Data</a></strong></p>
<ul>
<li><p>Identifying Missing Data</p></li>
<li><p>Dealing with Missing Data</p></li>
</ul>
</li>
<li><p><strong><a class="reference external" href="#format-the-data">Formatting the Data for Decision Trees</a></strong></p>
<ul>
<li><p>Splitting data into Dependent and Independent Variables</p></li>
<li><p>One-Hot-Encoding</p></li>
</ul>
</li>
<li><p><strong><a class="reference external" href="#build-tree">Building a Preliminary Classification Tree</a></strong></p></li>
<li><p><strong><a class="reference external" href="#prune-tree">Optimzing the tree with Cost Complexity Pruning</a></strong></p>
<ul>
<li><p>Visualizing Alpha</p></li>
<li><p>Using Cross Validation to find the best value for Alpha</p></li>
</ul>
</li>
<li><p><strong><a class="reference external" href="#draw-tree">Building, Drawing, Interpreting and Evaluating the Final Classification Tree</a></strong></p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<div class="section" id="import-the-modules">
<h2><span class="section-number">14.1. </span>Import the modules<a class="headerlink" href="#import-the-modules" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> <span class="c1"># to load and manipulate data and for One-Hot Encoding</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> <span class="c1"># to calculate the mean and standard deviation</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span> <span class="c1"># to draw graphs</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span> <span class="c1"># to build a classification tree</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">plot_tree</span> <span class="c1"># to draw a classification tree</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span> <span class="c1"># to split data into training and testing sets</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span> <span class="c1"># for cross validation</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span> <span class="c1"># to create a confusion matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">plot_confusion_matrix</span> <span class="c1"># to draw a confusion matrix</span>

<span class="kn">from</span> <span class="nn">pandas_profiling</span> <span class="kn">import</span> <span class="n">ProfileReport</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">FloatProgress</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>jupyter nbextension <span class="nb">enable</span> --py widgetsnbextension
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Enabling notebook extension jupyter-js-widgets/extension...
      - Validating: <span class=" -Color -Color-Green">OK</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<p><a id="download-the-data"></a></p>
</div>
<div class="section" id="import-the-data">
<h2><span class="section-number">14.2. </span>Import the data<a class="headerlink" href="#import-the-data" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;processed.cleveland.data&#39;</span><span class="p">,</span> 
                 <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1">## 要自己下載也可以</span>
<span class="c1"># df = pd.read_csv(&#39;https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data&#39;, </span>
<span class="c1">#                  header=None)</span>

<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;sex&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;cp&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;restbp&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;chol&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;fbs&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;restecg&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;thalach&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;exang&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;oldpeak&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;slope&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;ca&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;thal&#39;</span><span class="p">,</span> 
              <span class="s1">&#39;hd&#39;</span><span class="p">]</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>sex</th>
      <th>cp</th>
      <th>restbp</th>
      <th>chol</th>
      <th>fbs</th>
      <th>restecg</th>
      <th>thalach</th>
      <th>exang</th>
      <th>oldpeak</th>
      <th>slope</th>
      <th>ca</th>
      <th>thal</th>
      <th>hd</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>63.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>145.0</td>
      <td>233.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>150.0</td>
      <td>0.0</td>
      <td>2.3</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>6.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>67.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>160.0</td>
      <td>286.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>108.0</td>
      <td>1.0</td>
      <td>1.5</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>67.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>120.0</td>
      <td>229.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>129.0</td>
      <td>1.0</td>
      <td>2.6</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>7.0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>37.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>130.0</td>
      <td>250.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>187.0</td>
      <td>0.0</td>
      <td>3.5</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>41.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>130.0</td>
      <td>204.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>172.0</td>
      <td>0.0</td>
      <td>1.4</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="id1">
<h2><span class="section-number">14.3. </span>資料檢查 &amp; 清理<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>從上表看起來，每一欄都是數字，但其實他是把類別型的也用數字呈現了。</p></li>
<li><p>說明一下各欄位的意義：</p>
<ul>
<li><p><strong>age</strong>, <strong>Float</strong></p></li>
<li><p><strong>sex</strong> - <strong>Category</strong></p>
<ul>
<li><p>0 = female</p></li>
<li><p>1 = male</p></li>
</ul>
</li>
<li><p><strong>cp</strong>, chest pain, 胸痛, <strong>Category</strong></p>
<ul>
<li><p>1 = typical angina</p></li>
<li><p>2 = atypical angina</p></li>
<li><p>3 = non-anginal pain</p></li>
<li><p>4 = asymptomatic</p></li>
</ul>
</li>
<li><p><strong>restbp</strong>, resting blood pressure (in mm Hg),靜止血壓, <strong>Float</strong></p></li>
<li><p><strong>chol</strong>, serum cholesterol in mg/dl, 血清膽固醇, <strong>Float</strong></p></li>
<li><p><strong>fbs</strong>, fasting blood sugar, 飯前血糖, <strong>Category</strong></p>
<ul>
<li><p>0 = &gt;=120 mg/dl</p></li>
<li><p>1 = &lt;120 mg/dl</p></li>
</ul>
</li>
<li><p><strong>restecg</strong>, resting electrocardiographic results, 靜態心電圖結果, <strong>Category</strong></p>
<ul>
<li><p>1 = normal</p></li>
<li><p>2 = having ST-T wave abnormality</p></li>
<li><p>3 = showing probable or definite left ventricular hypertrophy</p></li>
</ul>
</li>
<li><p><strong>thalach</strong>,  maximum heart rate achieved, 最高心跳率, <strong>Float</strong></p></li>
<li><p><strong>exang</strong>, exercise induced angina, 運動造成的心絞痛, <strong>Category</strong></p>
<ul>
<li><p>0 = no</p></li>
<li><p>1 = yes</p></li>
</ul>
</li>
<li><p><strong>oldpeak</strong>, ST depression induced by exercise relative to rest. 心電圖的ST段波形下沉的程度 -&gt; 心肌梗塞的現象, <strong>Float</strong></p></li>
<li><p><strong>slope</strong>, the slope of the peak exercise ST segment, 心電圖的ST段的斜率, <strong>Category</strong></p>
<ul>
<li><p>1 = upsloping</p></li>
<li><p>2 = flat</p></li>
<li><p>3 = downsloping</p></li>
</ul>
</li>
<li><p><strong>ca</strong>, number of major vessels (0-3) colored by fluoroscopy, 幾條大血管有被螢光劑染色, <strong>Float</strong></p></li>
<li><p><strong>thal</strong>, thalium heart scan, 心肌灌流掃描(thalium是鉈-201，掃描時要注射的放射劑), <strong>Category</strong></p>
<ul>
<li><p>3 = normal (no cold spots)</p></li>
<li><p>6 = fixed defect (cold spots during rest and exercise)</p></li>
<li><p>7 = reversible defect (when cold spots only appear during exercise)</p></li>
</ul>
</li>
<li><p><strong>hd</strong>, diagnosis of heart disease, the predicted attribute 心臟病診斷結果，我們的 y</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>我先將資料類型整理如下：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">categorical_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;sex&quot;</span><span class="p">,</span> <span class="s2">&quot;cp&quot;</span><span class="p">,</span> <span class="s2">&quot;fbs&quot;</span><span class="p">,</span> <span class="s2">&quot;restecg&quot;</span><span class="p">,</span> <span class="s2">&quot;exang&quot;</span><span class="p">,</span> <span class="s2">&quot;slope&quot;</span><span class="p">,</span> <span class="s2">&quot;thal&quot;</span><span class="p">]</span>
<span class="n">numerical_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;age&quot;</span><span class="p">,</span> <span class="s2">&quot;restbp&quot;</span><span class="p">,</span> <span class="s2">&quot;chol&quot;</span><span class="p">,</span> <span class="s2">&quot;thalach&quot;</span><span class="p">,</span> <span class="s2">&quot;oldpeak&quot;</span><span class="p">,</span> <span class="s2">&quot;ca&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>來看一下目前的資料 type</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 303 entries, 0 to 302
Data columns (total 14 columns):
 #   Column   Non-Null Count  Dtype  
---  ------   --------------  -----  
 0   age      303 non-null    float64
 1   sex      303 non-null    float64
 2   cp       303 non-null    float64
 3   restbp   303 non-null    float64
 4   chol     303 non-null    float64
 5   fbs      303 non-null    float64
 6   restecg  303 non-null    float64
 7   thalach  303 non-null    float64
 8   exang    303 non-null    float64
 9   oldpeak  303 non-null    float64
 10  slope    303 non-null    float64
 11  ca       303 non-null    object 
 12  thal     303 non-null    object 
 13  hd       303 non-null    int64  
dtypes: float64(11), int64(1), object(2)
memory usage: 33.3+ KB
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>發現蠻怪的，剛剛看表格，全都是數字，所以應該都要被判讀為 float64，但 <strong>ca</strong> and <strong>thal</strong>, 卻呈現是<code class="docutils literal notranslate"><span class="pre">object</span></code>，表示資料裡面有 mixtures of things (例如數字 + 字母)，但，<strong>ca(幾條血管被螢光劑染色)</strong> 和 <strong>thal(心機灌流掃描的結果)</strong> 應該就是數值，所以我們來檢查看看</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;ca&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;0.0&#39;, &#39;3.0&#39;, &#39;2.0&#39;, &#39;1.0&#39;, &#39;?&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>我們發現，<strong>ca</strong> 應該只有 0, 3, 2, 1 這四種值，但多出來 <code class="docutils literal notranslate"><span class="pre">?</span></code> ，可見 <code class="docutils literal notranslate"><span class="pre">?</span></code> 就是個 missing data</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;thal&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;6.0&#39;, &#39;3.0&#39;, &#39;7.0&#39;, &#39;?&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>一樣，都有 <code class="docutils literal notranslate"><span class="pre">?</span></code> 在搗亂</p></li>
</ul>
<p><a id="identify-and-deal-with-missing-data"></a></p>
<div class="section" id="identify-deal-with-missing-data">
<h3><span class="section-number">14.3.1. </span>identify &amp; deal with missing data<a class="headerlink" href="#identify-deal-with-missing-data" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>剛剛有檢查到，他的 NA 是標成 <code class="docutils literal notranslate"><span class="pre">?</span></code>.</p></li>
<li><p>現在把 <code class="docutils literal notranslate"><span class="pre">?</span></code> 換成 python 看得懂的 NA 的樣子吧：</p>
<ul>
<li><p>python中，對文字類型的 NA 叫 None，對數值類型的NA 叫 np.nan;</p></li>
<li><p>R 的 <a class="reference external" href="http://is.na">is.na</a>() 在 python 叫 isnull()，他會偵測出 None 和 np.nan</p></li>
<li><p>R 的 !<a class="reference external" href="http://is.na">is.na</a>() 在 python 叫 notnull()</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">ca</span> <span class="o">==</span> <span class="s2">&quot;?&quot;</span><span class="p">,</span> <span class="s2">&quot;ca&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span> 
<span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">thal</span> <span class="o">==</span> <span class="s2">&quot;?&quot;</span><span class="p">,</span> <span class="s2">&quot;thal&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 303 entries, 0 to 302
Data columns (total 14 columns):
 #   Column   Non-Null Count  Dtype  
---  ------   --------------  -----  
 0   age      303 non-null    float64
 1   sex      303 non-null    float64
 2   cp       303 non-null    float64
 3   restbp   303 non-null    float64
 4   chol     303 non-null    float64
 5   fbs      303 non-null    float64
 6   restecg  303 non-null    float64
 7   thalach  303 non-null    float64
 8   exang    303 non-null    float64
 9   oldpeak  303 non-null    float64
 10  slope    303 non-null    float64
 11  ca       299 non-null    object 
 12  thal     301 non-null    object 
 13  hd       303 non-null    int64  
dtypes: float64(11), int64(1), object(2)
memory usage: 33.3+ KB
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>sklearn 的 classification tree 無法處理 missing values，所以我們有兩種處理方法：</p>
<ul>
<li><p>刪除整列</p></li>
<li><p>補值</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>因為 missing 的很少，所以這邊直接整列刪除就</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_no_missing</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;original rows: &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;nonmissing rows: &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_no_missing</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>original rows:  303
nonmissing rows:  297
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cat_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;cp&#39;</span><span class="p">,</span> <span class="s1">&#39;restecg&#39;</span><span class="p">,</span> <span class="s1">&#39;slope&#39;</span><span class="p">,</span> <span class="s1">&#39;thal&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cat_cols</span><span class="p">:</span>
    <span class="n">df_no_missing</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_no_missing</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;object&quot;</span><span class="p">)</span>
<span class="n">df_no_missing</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Int64Index: 297 entries, 0 to 301
Data columns (total 14 columns):
 #   Column   Non-Null Count  Dtype  
---  ------   --------------  -----  
 0   age      297 non-null    float64
 1   sex      297 non-null    float64
 2   cp       297 non-null    object 
 3   restbp   297 non-null    float64
 4   chol     297 non-null    float64
 5   fbs      297 non-null    float64
 6   restecg  297 non-null    object 
 7   thalach  297 non-null    float64
 8   exang    297 non-null    float64
 9   oldpeak  297 non-null    float64
 10  slope    297 non-null    object 
 11  ca       297 non-null    object 
 12  thal     297 non-null    object 
 13  hd       297 non-null    int64  
dtypes: float64(8), int64(1), object(5)
memory usage: 34.8+ KB
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/var/folders/j9/71c8r2vs343cb9329xbww0240000gn/T/ipykernel_43117/3365937875.py:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_no_missing.loc[:, col] = df_no_missing[col].astype(&quot;object&quot;)
</pre></div>
</div>
</div>
</div>
<p><a id="format-the-data"></a></p>
</div>
</div>
<div class="section" id="format-data-part-1-y-and-x-form">
<h2><span class="section-number">14.4. </span>Format Data Part 1: Y and X form<a class="headerlink" href="#format-data-part-1-y-and-x-form" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>接下來，要把資料做成可以餵進去 sklean 的樣子</p></li>
</ul>
<p><strong>ALSO NOTE:</strong> In the code below we are using <code class="docutils literal notranslate"><span class="pre">copy()</span></code> to copy the data <em>by value</em>. By default, pandas uses copy <em>by reference</em>. Using <code class="docutils literal notranslate"><span class="pre">copy()</span></code> ensures that the original data <code class="docutils literal notranslate"><span class="pre">df_no_missing</span></code> is not modified when we modify <code class="docutils literal notranslate"><span class="pre">X</span></code> or <code class="docutils literal notranslate"><span class="pre">y</span></code>. In other words, if we make a mistake when we are formatting the columns for classification trees, we can just re-copy <code class="docutils literal notranslate"><span class="pre">df_no_missing</span></code>, rather than reload the original data and remove the missing values etc.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df_no_missing</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;hd&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="c1"># 用 copy 的方式來做，才不會等等改 X 時， df_nomissing 跟著變</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_no_missing</span><span class="p">[</span><span class="s1">&#39;hd&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">[</span><span class="n">y</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">clf_dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">ccp_alpha</span><span class="o">=</span><span class="mf">0.014</span><span class="p">)</span>
<span class="n">clf_dt</span> <span class="o">=</span> <span class="n">clf_dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mf">7.5</span><span class="p">))</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">clf_dt</span><span class="p">,</span> 
          <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
          <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
          <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;No HD&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes HD&quot;</span><span class="p">],</span> 
          <span class="n">feature_names</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">);</span> 
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<p><a id="one-hot-encoding"></a></p>
</div>
<div class="section" id="format-the-data-part-2-one-hot-encoding">
<h2><span class="section-number">14.5. </span>Format the Data Part 2: One-Hot Encoding<a class="headerlink" href="#format-the-data-part-2-one-hot-encoding" title="Permalink to this headline">¶</a></h2>
<p>Now that we have split the dataframe into two pieces, <code class="docutils literal notranslate"><span class="pre">X</span></code>, which contains the data we will use to  predict classifications, and <code class="docutils literal notranslate"><span class="pre">y</span></code>, which contains the known classifications in our training dataset, we need to take a closer look at the variables in <code class="docutils literal notranslate"><span class="pre">X</span></code>. The list bellow tells us what each variable represents and the type of data (<strong>float</strong> or <strong>categorical</strong>) it should contain:</p>
<ul class="simple">
<li><p><strong>age</strong>, <strong>Float</strong></p></li>
<li><p><strong>sex</strong> - <strong>Category</strong></p>
<ul>
<li><p>0 = female</p></li>
<li><p>1 = male</p></li>
</ul>
</li>
<li><p><strong>cp</strong>, chest pain, <strong>Category</strong></p>
<ul>
<li><p>1 = typical angina</p></li>
<li><p>2 = atypical angina</p></li>
<li><p>3 = non-anginal pain</p></li>
<li><p>4 = asymptomatic</p></li>
</ul>
</li>
<li><p><strong>restbp</strong>, resting blood pressure (in mm Hg), <strong>Float</strong></p></li>
<li><p><strong>chol</strong>, serum cholesterol in mg/dl, <strong>Float</strong></p></li>
<li><p><strong>fbs</strong>, fasting blood sugar, <strong>Category</strong></p>
<ul>
<li><p>0 = &gt;=120 mg/dl</p></li>
<li><p>1 = &lt;120 mg/dl</p></li>
</ul>
</li>
<li><p><strong>restecg</strong>, resting electrocardiographic results, <strong>Category</strong></p>
<ul>
<li><p>1 = normal</p></li>
<li><p>2 = having ST-T wave abnormality</p></li>
<li><p>3 = showing probable or definite left ventricular hypertrophy</p></li>
</ul>
</li>
<li><p><strong>thalach</strong>,  maximum heart rate achieved, <strong>Float</strong></p></li>
<li><p><strong>exang</strong>, exercise induced angina, <strong>Category</strong></p>
<ul>
<li><p>0 = no</p></li>
<li><p>1 = yes</p></li>
</ul>
</li>
<li><p><strong>oldpeak</strong>, ST depression induced by exercise relative to rest. <strong>Float</strong></p></li>
<li><p><strong>slope</strong>, the slope of the peak exercise ST segment, <strong>Category</strong></p>
<ul>
<li><p>1 = upsloping</p></li>
<li><p>2 = flat</p></li>
<li><p>3 = downsloping</p></li>
</ul>
</li>
<li><p><strong>ca</strong>, number of major vessels (0-3) colored by fluoroscopy, <strong>Float</strong></p></li>
<li><p><strong>thal</strong>, thalium heart scan, <strong>Category</strong></p>
<ul>
<li><p>3 = normal (no cold spots)</p></li>
<li><p>6 = fixed defect (cold spots during rest and exercise)</p></li>
<li><p>7 = reversible defect (when cold spots only appear during exercise)</p></li>
</ul>
</li>
</ul>
<p>Now, just to review, let’s look at the data types in <code class="docutils literal notranslate"><span class="pre">X</span></code> to remember how python is seeing the data right now.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">dtypes</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>age        float64
sex        float64
cp          object
restbp     float64
chol       float64
fbs        float64
restecg     object
thalach    float64
exang      float64
oldpeak    float64
slope       object
ca          object
thal        object
dtype: object
</pre></div>
</div>
</div>
</div>
<p>So, we see that <strong>age</strong>, <strong>restbp</strong>, <strong>chol</strong> and <strong>thalach</strong> are all <code class="docutils literal notranslate"><span class="pre">float64</span></code>, which is good, because we want them to be floating point numbers. All of the other columns, however, need to be inspected to make sure they only contain reasonable values, and some of them need to change. This is because, while <strong>scikit learn Decision Trees</strong> natively support continuous data, like resting blood preasure (<strong>restbp</strong>) and maximum heart rate (<strong>thalach</strong>), they do not natively support categorical data, like chest pain (<strong>cp</strong>), which contains 4 different categories. Thus, in order to use categorical data with <strong>scikit learn Decision Trees</strong>, we have to use a trick that converts a column of categorical data into multiple columns of binary values. This trick is called <strong>One-Hot Encoding</strong>.</p>
<p>At this point you may be wondering, “what’s wrong with treating categorical data like continuous data?” To answer that question, let’s look at an example: For the <strong>cp</strong> (chest pain) column, we have 4 options:</p>
<ol class="simple">
<li><p>typical angina</p></li>
<li><p>atypical angina</p></li>
<li><p>non-anginal pain</p></li>
<li><p>asymptomatic</p></li>
</ol>
<p>If we treated these values, 1, 2, 3 and 4, like continuous data, then we would assume that 4, which means “asymptomatic”, is more similar to 3, which means “non-anginal pain”, than it is to 1 or 2, which are other types of chest pain. That means the decision tree would be more likely to cluster the patients with 4s and 3s together than the patients with 4s and 1s together. In contrast, if we treat these numbers like categorical data, then we treat each one as a separate category that is no more or less similar to any of the other categories. Thus, the likelihood of clustering patients with 4s with 3s is the same as clustering 4s with 1s, and that approach is more reasonable.</p>
<p>Now let’s inspect and, if needed, convert the columns that contain categorical and integer data into the correct datatypes. We’ll start with <strong>cp</strong> (chest pain) by inspecting all of its unique values:</p>
<!-- We'll start with the three colunms that should only contain 0s and 1s. **sex**. First, let's make sure it only contains `0` (for **female**) and `1` (for **male**). --><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">[</span><span class="s1">&#39;cp&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.0, 4.0, 3.0, 2.0], dtype=object)
</pre></div>
</div>
</div>
</div>
<p>So, the good news is that <strong>cp</strong> only contains the values it is supposed to contain, so we will convert it, using <strong>One-Hot Encoding</strong>, into a series of columns that only contains <strong>0s</strong> and <strong>1s</strong>.</p>
<!-- Now we need to deal with **cp** (chest pain), **restecg** (resting electrocardiographic results), **slope** (the slope of the peak exercise ST segment) and **thal** (thalium heart scan).
 -->
<p><strong>NOTE:</strong> There are many different ways to do <strong>One-Hot Encoding</strong> in Python. Two of the more popular methods are <code class="docutils literal notranslate"><span class="pre">ColumnTransformer()</span></code> (from <strong>scikit-learn</strong>) and <code class="docutils literal notranslate"><span class="pre">get_dummies()</span></code> (from <strong>pandas</strong>), and the both methods have pros and cons. <code class="docutils literal notranslate"><span class="pre">ColumnTransformer()</span></code> has a very cool feature where it creates a persistent function that can validate data that you get in the future. For example, if you build your <strong>Decision Tree</strong> using a categorical variable <strong>favorite color</strong> that has <strong>red</strong>, <strong>blue</strong> and <strong>green</strong> options, then <code class="docutils literal notranslate"><span class="pre">ColumnTransformer()</span></code> can remember those options and later on when your <strong>Decision Tree</strong> is being used in a production system, if someone says their favorite color is <strong>orange</strong>, then <code class="docutils literal notranslate"><span class="pre">ColumnTransformer()</span></code> can throw an error or handle the situation in some other nice way. The downside of <code class="docutils literal notranslate"><span class="pre">ColumnTransformer()</span></code> is that it turns your data into an array and looses all of the column names, making it harder to verify that your usage of <code class="docutils literal notranslate"><span class="pre">ColumnTransformer()</span></code> worked as you intended it to. In contrast, <code class="docutils literal notranslate"><span class="pre">get_dummies()</span></code> leaves your data in a dataframe and retains the column names, making it much easier to verify that it worked as intended. However, it does not have the persistent behavior that <code class="docutils literal notranslate"><span class="pre">ColumnTransformer()</span></code> has. So, for the sake of learning how <strong>One-Hot Encoding</strong> works, I prefer to use <code class="docutils literal notranslate"><span class="pre">get_dummies()</span></code>. However, once you are comfortable with <strong>One-Hot Encoding</strong>, I encourage you to investigate using <code class="docutils literal notranslate"><span class="pre">ColumnTransformer()</span></code>.</p>
<p>First, before we commit to converting <strong>cp</strong> with <strong>One-Hot Encoding</strong>, let’s just see what happens when we convert <strong>cp</strong> without saving the results. This will make it easy to see how <code class="docutils literal notranslate"><span class="pre">get_dummies()</span></code> works.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## For this tutorial, we will use get_dummies() to do One-Hot Encoding,</span>
<span class="c1">## but just know that there are other options.</span>
<span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;cp&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Volumes/GoogleDrive/我的雲端硬碟/0. codepool_python/python_ds/python_ds_env/lib/python3.8/site-packages/pandas/core/algorithms.py:794: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)
  uniques = Index(uniques)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>sex</th>
      <th>restbp</th>
      <th>chol</th>
      <th>fbs</th>
      <th>restecg</th>
      <th>thalach</th>
      <th>exang</th>
      <th>oldpeak</th>
      <th>slope</th>
      <th>ca</th>
      <th>thal</th>
      <th>cp_1.0</th>
      <th>cp_2.0</th>
      <th>cp_3.0</th>
      <th>cp_4.0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>63.0</td>
      <td>1.0</td>
      <td>145.0</td>
      <td>233.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>150.0</td>
      <td>0.0</td>
      <td>2.3</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>6.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>67.0</td>
      <td>1.0</td>
      <td>160.0</td>
      <td>286.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>108.0</td>
      <td>1.0</td>
      <td>1.5</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>67.0</td>
      <td>1.0</td>
      <td>120.0</td>
      <td>229.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>129.0</td>
      <td>1.0</td>
      <td>2.6</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>7.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>37.0</td>
      <td>1.0</td>
      <td>130.0</td>
      <td>250.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>187.0</td>
      <td>0.0</td>
      <td>3.5</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>41.0</td>
      <td>0.0</td>
      <td>130.0</td>
      <td>204.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>172.0</td>
      <td>0.0</td>
      <td>1.4</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>As we can see in the printout above, <code class="docutils literal notranslate"><span class="pre">get_dummies()</span></code> puts all of the columns it does not process in the front and it puts <strong>cp</strong> at the end. It also splits <strong>cp</strong> into <strong>4</strong> columns, just like we expected it. <strong>cp_1.0</strong> is <code class="docutils literal notranslate"><span class="pre">1</span></code> for any patient that scored a <strong>1</strong> for chest pain and <code class="docutils literal notranslate"><span class="pre">0</span></code> for all other patients. <strong>cp_2.0</strong> is <code class="docutils literal notranslate"><span class="pre">1</span></code> for any patient that scored <strong>2</strong> for chest pain and <code class="docutils literal notranslate"><span class="pre">0</span></code> for all other patients. <strong>cp_3.0</strong> is <code class="docutils literal notranslate"><span class="pre">1</span></code> for any patient that scored <strong>3</strong> for chest pain and <strong>cp_4.0</strong> is <code class="docutils literal notranslate"><span class="pre">1</span></code> for any patient that scored <strong>4</strong> for chest pain.</p>
<p>Now that we see how <code class="docutils literal notranslate"><span class="pre">get_dummies()</span></code> works, let’s use it on the four categorical columns that have more than 2 categories and save the result.</p>
<p><strong>NOTE:</strong> In a real situation (not a tutorial like this), you should verify all 5 of these columns
only contain the accepted categories. However, for this tutorial, I’ve already done that for us, so we can skip that step.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_encoded</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;cp&#39;</span><span class="p">,</span> 
                                       <span class="s1">&#39;restecg&#39;</span><span class="p">,</span> 
                                       <span class="s1">&#39;slope&#39;</span><span class="p">,</span> 
                                       <span class="s1">&#39;thal&#39;</span><span class="p">])</span>
<span class="n">X_encoded</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Volumes/GoogleDrive/我的雲端硬碟/0. codepool_python/python_ds/python_ds_env/lib/python3.8/site-packages/pandas/core/algorithms.py:794: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)
  uniques = Index(uniques)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>sex</th>
      <th>restbp</th>
      <th>chol</th>
      <th>fbs</th>
      <th>thalach</th>
      <th>exang</th>
      <th>oldpeak</th>
      <th>ca</th>
      <th>cp_1.0</th>
      <th>...</th>
      <th>cp_4.0</th>
      <th>restecg_0.0</th>
      <th>restecg_1.0</th>
      <th>restecg_2.0</th>
      <th>slope_1.0</th>
      <th>slope_2.0</th>
      <th>slope_3.0</th>
      <th>thal_3.0</th>
      <th>thal_6.0</th>
      <th>thal_7.0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>63.0</td>
      <td>1.0</td>
      <td>145.0</td>
      <td>233.0</td>
      <td>1.0</td>
      <td>150.0</td>
      <td>0.0</td>
      <td>2.3</td>
      <td>0.0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>67.0</td>
      <td>1.0</td>
      <td>160.0</td>
      <td>286.0</td>
      <td>0.0</td>
      <td>108.0</td>
      <td>1.0</td>
      <td>1.5</td>
      <td>3.0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>67.0</td>
      <td>1.0</td>
      <td>120.0</td>
      <td>229.0</td>
      <td>0.0</td>
      <td>129.0</td>
      <td>1.0</td>
      <td>2.6</td>
      <td>2.0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>37.0</td>
      <td>1.0</td>
      <td>130.0</td>
      <td>250.0</td>
      <td>0.0</td>
      <td>187.0</td>
      <td>0.0</td>
      <td>3.5</td>
      <td>0.0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>41.0</td>
      <td>0.0</td>
      <td>130.0</td>
      <td>204.0</td>
      <td>0.0</td>
      <td>172.0</td>
      <td>0.0</td>
      <td>1.4</td>
      <td>0.0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 22 columns</p>
</div></div></div>
</div>
</div>
<div class="section" id="bam">
<h2><span class="section-number">14.6. </span>BAM!!!<a class="headerlink" href="#bam" title="Permalink to this headline">¶</a></h2>
<p>Now we need to talk about the <strong>3</strong> categorical columns that only contain <strong>0</strong>s and <strong>1</strong>s: <strong>sex</strong>, <strong>fbs</strong> (fasting blood sugar), and <strong>exang</strong> (exercise induced angina). As we can see, <strong>One-Hot Encoding</strong> converts a column with more than <strong>2</strong> categories, like <strong>cp</strong> (chest pain) into multiple columns of <strong>0</strong>s and <strong>1</strong>s. Since <strong>sex</strong>, <strong>fbs</strong>, and <strong>exang</strong> only have <strong>2</strong> categories and only contain <strong>0</strong>s and <strong>1</strong>s to begin with, we do not have to do anything special to them, so we’re done formatting the data for the <strong>Classification Tree</strong>.</p>
<p><strong>NOTE:</strong> In practice we would use <code class="docutils literal notranslate"><span class="pre">unique()</span></code> to verify that they only contain <strong>0</strong>s and <strong>1</strong>s, but to save time…trust me!</p>
<p>Now, one last thing before we build a <strong>Classification Tree</strong>.  <code class="docutils literal notranslate"><span class="pre">y</span></code> doesn’t just contain <strong>0</strong>s and <strong>1</strong>s. Instead, it has <strong>5</strong> different levels of heart disease. <strong>0 =</strong> no heart disease and <strong>1-4</strong> are various degrees of heart disease. We can see this with <code class="docutils literal notranslate"><span class="pre">unique()</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0, 1])
</pre></div>
</div>
</div>
</div>
<p>In this tutorial we’re only making a tree that does simple classification and only care if someone has heart disease or not, so we need to convert all numbers <strong>&gt; 0</strong> to <strong>1</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_not_zero_index</span> <span class="o">=</span> <span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="c1"># get the index for each non-zero value in y</span>
<span class="n">y</span><span class="p">[</span><span class="n">y_not_zero_index</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># set each non-zero value in y to 1</span>
<span class="n">y</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>               <span class="c1"># verify that y only contains 0 and 1.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0, 1])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="double-bam">
<h2><span class="section-number">14.7. </span>Double BAM!!!<a class="headerlink" href="#double-bam" title="Permalink to this headline">¶</a></h2>
<p>We have finally finished formatting the data for making a <strong>Classification Tree</strong>, so let’s do it!!!</p>
<hr class="docutils" />
<p><a id="build-tree"></a></p>
</div>
<div class="section" id="build-a-preliminary-classification-tree">
<h2><span class="section-number">14.8. </span>Build A Preliminary Classification Tree<a class="headerlink" href="#build-a-preliminary-classification-tree" title="Permalink to this headline">¶</a></h2>
<p>At long last, the data are correctly formatted for making a <strong>Classification Tree</strong>. Now we simply split the data into <strong>training</strong> and <strong>testing</strong> sets and build the tree.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## split the data into training and testing sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_encoded</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1">## create a decisiont tree and fit it to the training data</span>
<span class="n">clf_dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">clf_dt</span> <span class="o">=</span> <span class="n">clf_dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## NOTE: We can plot the tree and it is huge!</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mf">7.5</span><span class="p">))</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">clf_dt</span><span class="p">,</span> 
          <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
          <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
          <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;No HD&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes HD&quot;</span><span class="p">],</span> 
          <span class="n">feature_names</span><span class="o">=</span><span class="n">X_encoded</span><span class="o">.</span><span class="n">columns</span><span class="p">);</span> 
</pre></div>
</div>
</div>
</div>
<p>OK, we’ve built a <strong>Classification Tree</strong> for classification. Let’s see how it performs on the <strong>Testing Dataset</strong> by running the <strong>Testing Dataset</strong> down the tree and drawing a <strong>Confusion Matrix</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## plot_confusion_matrix() will run the test data down the tree and draw</span>
<span class="c1">## a confusion matrix.</span>
<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">clf_dt</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">display_labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Does not have HD&quot;</span><span class="p">,</span> <span class="s2">&quot;Has HD&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Volumes/GoogleDrive/我的雲端硬碟/0. codepool_python/python_ds/python_ds_env/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x13004dac0&gt;
</pre></div>
</div>
</div>
</div>
<p>In the confusion matrix, we see that of the <strong>31 + 11 = 42</strong> people that did not have <strong>Heart Disease</strong>, <strong>31 (74%)</strong> were correctly classified. And of the <strong>7 + 26 = 33</strong> people that have <strong>Heart Disease</strong>, <strong>26 (79%)</strong> were correctly classified. Can we do better? One thing that might be holding this <strong>Classification Tree</strong> back is that it may have <strong>overfit</strong> the training dataset. So let’s prune the tree. Pruning, in theory, should solve the overfitting problem and give us better results.</p>
<hr class="docutils" />
<p><a id="prune-tree"></a></p>
</div>
<div class="section" id="cost-complexity-pruning-part-1-visualize-alpha">
<h2><span class="section-number">14.9. </span>Cost Complexity Pruning Part 1: Visualize alpha<a class="headerlink" href="#cost-complexity-pruning-part-1-visualize-alpha" title="Permalink to this headline">¶</a></h2>
<p><strong>Decision Trees</strong> are notorious for being <strong>overfit</strong> to the <strong>Training Dataset</strong>, and there are a lot of parameters, like <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> and <code class="docutils literal notranslate"><span class="pre">min_samples</span></code>, that are designed to reduce overfitting. However, pruning a tree with <strong>cost complexity pruning</strong> can simplify the whole process of finding a smaller tree that impoves the accuracy with the <strong>Testing Dataset</strong>.</p>
<p>Pruning a decision tree is all about finding the right value for the pruning parameter, <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, which controls how little or how much pruning happens. One way to find the optimal value for <code class="docutils literal notranslate"><span class="pre">alpha</span></code> is to plot the accuracy of the tree as a function of different values.  We’ll do this for both the <strong>Training Dataset</strong> and the <strong>Testing Dataset</strong>.</p>
<p>First, let’s extract the different values of <code class="docutils literal notranslate"><span class="pre">alpha</span></code> that are available for this tree and build a pruned tree for each value for <code class="docutils literal notranslate"><span class="pre">alpha</span></code>. <strong>NOTE:</strong> We omit the maximum value for alpha with <code class="docutils literal notranslate"><span class="pre">ccp_alphas</span> <span class="pre">=</span> <span class="pre">ccp_alphas[:-1]</span></code> because it would prune all leaves, leaving us with only a root instead of a tree.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">clf_dt</span><span class="o">.</span><span class="n">cost_complexity_pruning_path</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># determine values for alpha</span>
<span class="n">ccp_alphas</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">ccp_alphas</span> <span class="c1"># extract different values for alpha</span>
<span class="n">ccp_alphas</span> <span class="o">=</span> <span class="n">ccp_alphas</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># exclude the maximum value for alpha</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">clf_dt</span><span class="o">.</span><span class="n">cost_complexity_pruning_path</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># determine values for alpha</span>
<span class="n">ccp_alphas</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">ccp_alphas</span> <span class="c1"># extract different values for alpha</span>
<span class="n">ccp_alphas</span> <span class="o">=</span> <span class="n">ccp_alphas</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># exclude the maximum value for alpha</span>

<span class="n">clf_dts</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># create an array that we will put decision trees into</span>

<span class="c1">## now create one decision tree per value for alpha and store it in the array</span>
<span class="k">for</span> <span class="n">ccp_alpha</span> <span class="ow">in</span> <span class="n">ccp_alphas</span><span class="p">:</span>
    <span class="n">clf_dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ccp_alpha</span><span class="o">=</span><span class="n">ccp_alpha</span><span class="p">)</span>
    <span class="n">clf_dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">clf_dts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clf_dt</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s graph the accuracy of the trees using the <strong>Training Dataset</strong> and the <strong>Testing Dataset</strong> as a function of alpha.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">clf_dt</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="k">for</span> <span class="n">clf_dt</span> <span class="ow">in</span> <span class="n">clf_dts</span><span class="p">]</span>
<span class="n">test_scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">clf_dt</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="k">for</span> <span class="n">clf_dt</span> <span class="ow">in</span> <span class="n">clf_dts</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;alpha&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Accuracy vs alpha for training and testing sets&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ccp_alphas</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">drawstyle</span><span class="o">=</span><span class="s2">&quot;steps-post&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ccp_alphas</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">drawstyle</span><span class="o">=</span><span class="s2">&quot;steps-post&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/var/folders/j9/71c8r2vs343cb9329xbww0240000gn/T/ipykernel_43117/3483475302.py:11: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show()
</pre></div>
</div>
</div>
</div>
<p>In the graph above, we see that the accuracy for the <strong>Testing Dataset</strong> hits its maximum value when <code class="docutils literal notranslate"><span class="pre">alpha</span></code> is about <strong>0.016</strong>. After this value for <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, the accuracy of the <strong>Training Dataset</strong> drops off and that suggests we should set <code class="docutils literal notranslate"><span class="pre">ccp_alpha=0.016</span></code>.</p>
<p><strong>NOTE:</strong> When we apply <strong>Cost Complexity Pruning</strong> to a <strong>Classification Tree</strong>, values for <code class="docutils literal notranslate"><span class="pre">alpha</span></code> go from 0 to 1, because GINI scores go from 0 to 1. In contrast, values for <code class="docutils literal notranslate"><span class="pre">alpha</span></code> for a <strong>Regression Tree</strong> can be much larger since the sum of squared residuals can, in theory, go from 0 to positive infinity.</p>
<p>Since there are many ways we could have divided the original dataset into <strong>Training</strong> and <strong>Testing</strong> datasets, how do we know we used the best <strong>Training Dataset</strong> and how do we know we used the best <strong>Testing Dataset</strong>? Typically, we answer this question with <strong>10-Fold Cross Validation</strong>. So that’s what we’re going to do now, and we’ll do it with the <code class="docutils literal notranslate"><span class="pre">cross_val_score()</span></code> function.</p>
</div>
<hr class="docutils" />
<div class="section" id="cost-complexity-pruning-part-2-cross-validation-for-finding-the-best-alpha">
<h2><span class="section-number">14.10. </span>Cost Complexity Pruning Part 2: Cross Validation For Finding the Best Alpha<a class="headerlink" href="#cost-complexity-pruning-part-2-cross-validation-for-finding-the-best-alpha" title="Permalink to this headline">¶</a></h2>
<p>The graph we just drew suggested one value for alpha, <strong>0.016</strong>, but another
set of data might suggest another optimal value.</p>
<!-- **Terminology Alert!!!** Since, ultimately, we have to decide on one value for `alpha`, and
the **Decision Tree** algorithm will not do this for us, `alpha` is called a **Hyperparameter** to differentiate it from the parameters that the **Decision Tree** algorithm can take care of on its own. -->
<p>First, let’s demonstrate that different training and testing datasets result in trees with different accuracies when we set <code class="docutils literal notranslate"><span class="pre">ccp_alpha=0.016</span></code>. We will do this by using the <code class="docutils literal notranslate"><span class="pre">cross_val_score()</span></code> function to generate different training and testing datasets and then train and test the tree with those datasets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf_dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">ccp_alpha</span><span class="o">=</span><span class="mf">0.016</span><span class="p">)</span> <span class="c1"># create the tree with ccp_alpha=0.016</span>

<span class="c1">## now use 5-fold cross validation create 5 different training and testing datasets that</span>
<span class="c1">## are then used to train and test the tree.</span>
<span class="c1">## NOTE: We use 5-fold because we don&#39;t have tons of data...</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf_dt</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> 
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;tree&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">scores</span><span class="p">})</span>

<span class="n">df</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;tree&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:xlabel=&#39;tree&#39;&gt;
</pre></div>
</div>
</div>
</div>
<p>The graph above shows that using different <strong>Training</strong> and <strong>Testing</strong> data with the same <code class="docutils literal notranslate"><span class="pre">alpha</span></code> resulted in different accuracies, suggesting that <code class="docutils literal notranslate"><span class="pre">alpha</span></code> is sensitive to the datasets. So, instead of picking a single <strong>Training</strong> dataset and single <strong>Testing</strong> dataset, let’s use <strong>cross validation</strong> to find the optimal value for <code class="docutils literal notranslate"><span class="pre">ccp_alpha</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## create an array to store the results of each fold during cross validiation</span>
<span class="n">alpha_loop_values</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">## For each candidate value for alpha, we will run 5-fold cross validation.</span>
<span class="c1">## Then we will store the mean and standard deviation of the scores (the accuracy) for each call</span>
<span class="c1">## to cross_val_score in alpha_loop_values...</span>
<span class="k">for</span> <span class="n">ccp_alpha</span> <span class="ow">in</span> <span class="n">ccp_alphas</span><span class="p">:</span>
    <span class="n">clf_dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ccp_alpha</span><span class="o">=</span><span class="n">ccp_alpha</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf_dt</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">alpha_loop_values</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">ccp_alpha</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">scores</span><span class="p">)])</span>

<span class="c1">## Now we can draw a graph of the means and standard deviations of the scores</span>
<span class="c1">## for each candidate value for alpha</span>
<span class="n">alpha_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">alpha_loop_values</span><span class="p">,</span> 
                             <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="s1">&#39;mean_accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;std&#39;</span><span class="p">])</span>

<span class="n">alpha_results</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span> 
                   <span class="n">y</span><span class="o">=</span><span class="s1">&#39;mean_accuracy&#39;</span><span class="p">,</span> 
                   <span class="n">yerr</span><span class="o">=</span><span class="s1">&#39;std&#39;</span><span class="p">,</span> 
                   <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> 
                   <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:xlabel=&#39;alpha&#39;&gt;
</pre></div>
</div>
</div>
</div>
<p>Using cross validation, we can see that, over all, instead of setting <code class="docutils literal notranslate"><span class="pre">ccp_alpha=0.016</span></code>,  we need to set it to something closer to <strong>0.014</strong>. We can find the exact value with:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alpha_results</span><span class="p">[(</span><span class="n">alpha_results</span><span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.014</span><span class="p">)</span>
              <span class="o">&amp;</span>
              <span class="p">(</span><span class="n">alpha_results</span><span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.015</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alpha</th>
      <th>mean_accuracy</th>
      <th>std</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>20</th>
      <td>0.014225</td>
      <td>0.747778</td>
      <td>0.091395</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now let’s store the ideal value for alpha so that we can use it to build the best tree.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ideal_ccp_alpha</span> <span class="o">=</span> <span class="n">alpha_results</span><span class="p">[(</span><span class="n">alpha_results</span><span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.014</span><span class="p">)</span> 
                                <span class="o">&amp;</span> 
                                <span class="p">(</span><span class="n">alpha_results</span><span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.015</span><span class="p">)][</span><span class="s1">&#39;alpha&#39;</span><span class="p">]</span>
<span class="n">ideal_ccp_alpha</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>20    0.014225
Name: alpha, dtype: float64
</pre></div>
</div>
</div>
</div>
<p><strong>NOTE:</strong> At this point Python thinks that <code class="docutils literal notranslate"><span class="pre">ideal_ccp_alpha</span></code> is a <code class="docutils literal notranslate"><span class="pre">series</span></code>, which is a type of array. We can tell because when we printed <code class="docutils literal notranslate"><span class="pre">ideal_ccp_alpha</span></code> out, we got two bits of stuff. The first one was <code class="docutils literal notranslate"><span class="pre">20</span></code>, which is the index in the series, the second one, <code class="docutils literal notranslate"><span class="pre">0.014225</span></code>, is the value we want. So we can convert this from a series to a float with the following command:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## convert ideal_ccp_alpha from a series to a float</span>
<span class="n">ideal_ccp_alpha</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">ideal_ccp_alpha</span><span class="p">)</span>
<span class="n">ideal_ccp_alpha</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.014224751066856332
</pre></div>
</div>
</div>
</div>
<p>Hooray!!! Now we have the ideal value for <code class="docutils literal notranslate"><span class="pre">alpha</span></code> and we can build, evaluate and draw the final <strong>Classification Tree</strong>.</p>
<hr class="docutils" />
<p><a id="draw-tree"></a></p>
</div>
<div class="section" id="building-evaluating-drawing-and-interpreting-the-final-classification-tree">
<h2><span class="section-number">14.11. </span>Building, Evaluating, Drawing, and Interpreting the Final Classification Tree<a class="headerlink" href="#building-evaluating-drawing-and-interpreting-the-final-classification-tree" title="Permalink to this headline">¶</a></h2>
<p>Now that we have the ideal value for <code class="docutils literal notranslate"><span class="pre">alpha</span></code> we can build the final <strong>Classification Tree</strong> by setting <code class="docutils literal notranslate"><span class="pre">ccp_alpha=ideal_ccp_alpha</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Build and train a new decision tree, only this time use the optimal value for alpha</span>
<span class="n">clf_dt_pruned</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> 
                                       <span class="n">ccp_alpha</span><span class="o">=</span><span class="n">ideal_ccp_alpha</span><span class="p">)</span>
<span class="n">clf_dt_pruned</span> <span class="o">=</span> <span class="n">clf_dt_pruned</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<p>Now let’s draw another confusion matrix to see if the pruned tree does better.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">clf_dt_pruned</span><span class="p">,</span> 
                      <span class="n">X_test</span><span class="p">,</span> 
                      <span class="n">y_test</span><span class="p">,</span> 
                      <span class="n">display_labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Does not have HD&quot;</span><span class="p">,</span> <span class="s2">&quot;Has HD&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Volumes/GoogleDrive/我的雲端硬碟/0. codepool_python/python_ds/python_ds_env/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.
  warnings.warn(msg, category=FutureWarning)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x13023bb80&gt;
</pre></div>
</div>
</div>
</div>
<p>Hooray!!! We see that the pruned tree is better at classifying patients than the full sized tree.</p>
<p>Of the <strong>34 + 8 = 42</strong> people that did not have heart disease, <strong>34 (81%)</strong> were correctly classified. This is an improvement over the full sized tree, which only correctly classified <strong>31 (74%)</strong> of the patients without heart disease. Of the <strong>5 + 28 = 33</strong> people with heart disease, <strong>28 (85%)</strong> were correctly classified. Again, this is an improvement over the full sized tree, which only correctly classified <strong>26 (79%)</strong> of the patients with heart disease. Yay for pruning!</p>
<p>The last thing we are going to do is draw the pruned tree and discuss how to interpret it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mf">7.5</span><span class="p">))</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">clf_dt_pruned</span><span class="p">,</span> 
          <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
          <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
          <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;No HD&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes HD&quot;</span><span class="p">],</span> 
          <span class="n">feature_names</span><span class="o">=</span><span class="n">X_encoded</span><span class="o">.</span><span class="n">columns</span><span class="p">);</span> 
</pre></div>
</div>
</div>
</div>
<p>Now let’s discuss how to interpret the tree.
In each node, we have:</p>
<ul class="simple">
<li><p>The variable (column name) and the threshold for splitting the observations. For example, in the tree’s root, we use <strong>ca</strong> to split the observations. All
observations with <strong>ca &lt;= 0.5</strong> go to the <strong>left</strong> and all observations with <strong>ca &gt; 0.5</strong> go to the <strong>right</strong>.</p></li>
<li><p><strong>gini</strong> is the gini index or score for that node</p></li>
<li><p><strong>samples</strong> tell us how many samples are in that node</p></li>
<li><p><strong>value</strong> tells us how many samples in the node are in each category. In this example, we have two categories, <strong>No</strong> and <strong>Yes</strong>, referring to whether or not a patient has heart disease. The number of patients with <strong>No</strong> comes first because the categories are in alphabetical order. Thus, in the root, 118 patients have <strong>No</strong> and 104 patients have <strong>Yes</strong>.</p></li>
<li><p><strong>class</strong> tells us whichever category is represented most in the node. In the root, since 118 people have <strong>No</strong> and only 104 people have <strong>Yes</strong>, class is set to <strong>No</strong>.</p></li>
</ul>
<p>The leaves are just like the nodes, except that they do not contain a variable and threshold for splitting the observations.</p>
<p>Lastly, the nodes and leaves are colored by the <strong>class</strong>. In this case <strong>No</strong> is different shades of orange-ish and <strong>Yes</strong> is different shades of blue. The the darker the shade, the lower the <strong>gini</strong> score, and that tells us how much the node or leaf is skewed towards one class.</p>
</div>
<hr class="docutils" />
<div class="section" id="in-conclusion-we">
<h2><span class="section-number">14.12. </span>In conclusion we…<a class="headerlink" href="#in-conclusion-we" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><strong><a class="reference external" href="#download-the-data">Imported Data</a></strong></p></li>
<li><p><strong><a class="reference external" href="#identify-and-deal-with-missing-data">Identified and Dealt with Missing Data</a></strong></p></li>
<li><p><strong><a class="reference external" href="#one-hot-encoding">Formatted the Data for Decision Trees using One-Hot Encoding</a></strong></p></li>
<li><p><strong><a class="reference external" href="#build-tree">Built a Preliminary Decision Tree for Classification</a></strong></p></li>
<li><p><strong><a class="reference external" href="#prune-tree">Pruned the Decision Tree with Cost Complexity Pruning</a></strong></p></li>
<li><p><strong><a class="reference external" href="#draw-tree">Built, Drew, Interpreted and Evaluated the Final Decision Tree</a></strong></p></li>
</ul>
</div>
<div class="section" id="triple-bam">
<h2><span class="section-number">14.13. </span>TRIPLE BAM!!!<a class="headerlink" href="#triple-bam" title="Permalink to this headline">¶</a></h2>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python_ds_env",
            path: "./statquest_trees"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python_ds_env'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../datacamp_su/datacamp_su.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">13. </span>Supervised Learning with scikit-learn</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../sklearn_guide/rf_permutation_imp.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">15. </span>Permutation Importance vs Random Forest Feature Importance (MDI)</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By The Jupyter Book Community<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>